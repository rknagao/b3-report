{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para manutenção do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import local_lib as lib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@st.cache\n",
    "def etl_tesouro_historic_price():\n",
    "    url = 'https://www.tesourotransparente.gov.br/ckan/dataset/df56aa42-484a-4a59-8184-7676580c81e3/resource/796d2059-14e9-44e3-80c9-2d9e30b405c1/download/PrecoTaxaTesouroDireto.csv'\n",
    "    df = pd.read_csv(url, sep=';', decimal=',')\n",
    "    df['data'] = pd.to_datetime(df['Data Base'], format='%d/%m/%Y')\n",
    "    df['ticker'] = df['Tipo Titulo'].astype(str) + ' ' + df['Data Vencimento'].str[6:]\n",
    "    df['preco_hist'] = round(df['PU Base Manha'].astype(float), 2)\n",
    "    return df\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "#@st.cache  \n",
    "def etl_benchmark_historic_price():\n",
    "    # CDI\n",
    "    df_cdi = pd.read_json('http://api.bcb.gov.br/dados/serie/bcdata.sgs.12/dados?formato=json')\n",
    "    df_cdi['data'] = pd.to_datetime(df_cdi['data'], format='%d/%m/%Y')\n",
    "    df_cdi.columns = ['data','cdi']\n",
    "\n",
    "    # IPCA\n",
    "    df_ipca = pd.read_json('http://api.bcb.gov.br/dados/serie/bcdata.sgs.433/dados?formato=json')\n",
    "    df_ipca['data'] = pd.to_datetime(df_ipca['data'], format='%d/%m/%Y')\n",
    "    df_ipca.columns = ['data','ipca']\n",
    "    df_ipca['ipca'] = round((1 + df_ipca['ipca']) ** (1/22) - 1, 6)\n",
    "\n",
    "    # IBOV\n",
    "    df_ibov = yf.download('^BVSP', interval='1d')['Adj Close'].reset_index(drop=False)\n",
    "    df_ibov.columns = ['data','ibov']\n",
    "    df_ibov['ibov'] = ((df_ibov['ibov'] / df_ibov['ibov'].shift(1) - 1) * 100).fillna(0).round(6)\n",
    "        \n",
    "    # S&P500\n",
    "    df_sp500 = yf.download('^GSPC', interval='1d')['Adj Close'].reset_index(drop=False)\n",
    "    df_sp500.columns = ['data','sp500']\n",
    "    df_sp500['sp500'] = ((df_sp500['sp500'] / df_sp500['sp500'].shift(1) - 1) * 100).fillna(5).round(6)\n",
    "\n",
    "    df_final = pd.merge(df_ibov, df_sp500, on='data', how='inner')\n",
    "    df_final = pd.merge(df_final, df_cdi, on='data', how='inner')\n",
    "    df_final = pd.merge(df_final, df_ipca, on='data', how='left')\n",
    "    df_final['ipca'] = df_final['ipca'].fillna(method='ffill')\n",
    "    df_final['data'] = pd.to_datetime(df_final['data'])\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "#@st.cache\n",
    "def etl_bolsa_historic_price(list_ticker_b3: list, start_date: str, end_date: str) -> np.array:\n",
    "\n",
    "    # Utilizando a api do yf\n",
    "    long_string = ' '.join([i + '.SA' for i in list_ticker_b3])\n",
    "    df_price = yf.download(long_string, start=start_date, end=end_date, group_by='column')['Adj Close'].reset_index()\n",
    "\n",
    "    # Ajustes na base\n",
    "    df_price.columns = ['data'] + list(list_ticker_b3)    \n",
    "    df_price['data'] = pd.to_datetime(df_price['data'])\n",
    "    df_price = df_price.fillna(0).round(2)\n",
    "    \n",
    "    return df_price"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra script\n",
    "uploaded_files = [\n",
    "    '../data/kenji/movimentacao-2019.xlsx',\n",
    "    '../data/kenji/movimentacao-2020.xlsx',\n",
    "    '../data/kenji/movimentacao-2021.xlsx',\n",
    "    '../data/kenji/movimentacao-2022.xlsx',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração.\n",
    "for i in uploaded_files:\n",
    "    df = pd.read_excel(i, engine='openpyxl')\n",
    "\n",
    "    # No primeiro caso criaremos um dataframe que consolidará todas as movimentações.\n",
    "    if i == uploaded_files[0]:\n",
    "        df_all = df\n",
    "    else:\n",
    "        df_all = pd.concat([df_all, df], axis=0, ignore_index=True).drop_duplicates(keep='last')\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamentos:\n",
    "# (geral) Nome e dtype.\n",
    "dict_dtype = {'credito_ou_debito': str,\n",
    "                'data': str,\n",
    "                'tp_movimento': str,\n",
    "                'ativo': str,\n",
    "                'instituicao': str,\n",
    "                'qt_abs': float,\n",
    "                'preco_mov': float,\n",
    "                'vl_total_abs': float}\n",
    "\n",
    "df_all.columns = list(dict_dtype.keys())\n",
    "df_all['preco_mov'].replace('-', 0, inplace=True)\n",
    "df_all['vl_total_abs'].replace('-', 0, inplace=True)\n",
    "df_all = df_all.astype(dict_dtype)\n",
    "df_all['data'] = pd.to_datetime(df_all['data'], format='%d/%m/%Y')\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check (apagar)\n",
    "df_all.loc[df_all['ativo'].str.contains('B3SA3')].sort_values('data')\n",
    "#df_all.loc[df_all['tp_movimento'].str.contains('Desdobro')].sort_values('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (geral) Nova variável: classificação do ativo.\n",
    "df_all['tp_ativo'] = np.select(\n",
    "    [\n",
    "        (df_all['ativo'].str.upper()).str.contains('TESOURO'),\n",
    "        df_all['ativo'].str.split(' - ', 0).str[0].str.len() == 5,\n",
    "        df_all['ativo'].str.split(' - ', 0).str[0].str.len() == 6,\n",
    "        df_all['ativo'].str.contains('DEB'),\n",
    "        df_all['ativo'].str.contains('|'.join(['CDB', 'RDB', 'LCA', 'LCI']))\n",
    "    ],\n",
    "    [\n",
    "        'Tipo 1: tesouro',\n",
    "        'Tipo 2: ações',\n",
    "        'Tipo 3: BDR',\n",
    "        'Tipo 4: debêntures',\n",
    "        'Tipo 5: renda fixa privada'\n",
    "    ],'?'\n",
    ")\n",
    "\n",
    "# (geral) Nova variável: ticker.\n",
    "df_all['ticker'] = np.select(\n",
    "    [\n",
    "        df_all['tp_ativo'] == 'Tipo 4: debêntures',\n",
    "        df_all['tp_ativo'] == 'Tipo 5: renda fixa privada'\n",
    "    ],\n",
    "    [   \n",
    "        df_all['ativo'].str[5:12],\n",
    "        df_all['ativo'].str[5:17]\n",
    "    ], df_all['ativo'].str.split(' - ').str[0]\n",
    ")\n",
    "\n",
    "# (bolsa) Ajuste específico de ações: zerar a quantidade de compra/venda em caso de dividendos e juros sobre capital próprio.\n",
    "df_all['qt_abs'] = np.where(df_all['tp_movimento'].isin(['Transferência - Liquidação', 'Bonificação em Ativos', 'Desdobro']), df_all['qt_abs'], 0)\n",
    "\n",
    "# (geral) Nova variável: variação na quantidade de ativos.\n",
    "df_all['qt'] = df_all['qt_abs'] * np.where(df_all['credito_ou_debito'] == 'Credito', 1, -1)\n",
    "\n",
    "# (geral) Nova variável: variação na quantidade no valor total.\n",
    "df_all['vl_total'] = df_all['vl_total_abs'] * np.where(df_all['credito_ou_debito'] == 'Credito', 1, -1)\n",
    "\n",
    "# (bolsa) Nova variável: flag se a negociação é um provento (dividendo, juros sobre capital próprio ou leilão)\n",
    "df_all['provento'] = np.where(df_all['tp_movimento'].isin(['Dividendo', 'Juros Sobre Capital Próprio', 'Fração em Ativos', 'Leilão de Fração']), 'provento', 'negociacao')\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check (apagar)\n",
    "\n",
    "a =df_all.loc[df_all['ticker'] == 'ITSA4'].sort_values('data')\n",
    "a#['provento'] = np.where(a['tp_movimento'].isin(['Dividendo', 'Juros Sobre Capital Próprio', 'Fração em Ativos', 'Leilão de Fração']), 1, 0)\n",
    "#a['provento'].value_counts()\n",
    "\n",
    "#a['negociacao_ou_provento'] = np.where(a['tp_movimento'].str.isin(['Transferência - Liquidação']))\n",
    "#a['qt_abs'] = np.where(a['tp_movimento'].isin(['Transferência - Liquidação', 'Bonificação em Ativos']), a['qt_abs'], 0)\n",
    "\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "#    display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (f) Unificar múltiplas compras/vendas em diferentes corretoras.\n",
    "# Essa etapa necessariamente é a última, pois aplicaremos cálculo sobre quantidade e preço.\n",
    "# Ao final, teremos o preço médio de compras/venda \n",
    "# tp_movimento foi removido pois podem haver compras e vendas o mesmo dia (caso de daytrade)\n",
    "#df_all = df_all.groupby(['tp_ativo','ticker','data']).agg({'qt':'sum', 'vl_total':'sum'}).reset_index(drop=False)\n",
    "#df_all['preco_mov'] = np.where(df_all['qt'] != 0, round(df_all['vl_total'] / df_all['qt'], 2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Futuro: criar uma visão geral de todos os investimento.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar apenas Tesouro para a página seguinte.\n",
    "def only_tesouro(df):\n",
    "    df = df.groupby(['tp_ativo','ticker','data']).agg({'qt':'sum', 'vl_total':'sum'}).reset_index(drop=False)\n",
    "    df['preco_mov'] = np.where(df['qt'] != 0, round(df['vl_total'] / df['qt'], 2), 0)\n",
    "    df = df.loc[df['tp_ativo'] == 'Tipo 1: tesouro'].sort_values(by=['ticker','data'], ascending=True)\n",
    "    \n",
    "    return df[['data', 'ticker', 'qt', 'preco_mov', 'vl_total']]\n",
    "\n",
    "df_tesouro = only_tesouro(df_all)\n",
    "df_tesouro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar ações e BDR para a página seguinte.\n",
    "def only_bolsa(df):\n",
    "    df = df.loc[(df['tp_ativo'] == 'Tipo 2: ações') | (df['tp_ativo'] == 'Tipo 3: BDR')].sort_values(by=['ticker','data'], ascending=True)\n",
    "    df = df[['data', 'ticker', 'tp_movimento', 'provento', 'qt', 'preco_mov', 'vl_total']]\n",
    "    df = df.groupby(['data', 'ticker','provento']).agg({'qt':'sum', 'vl_total':'sum'}).reset_index(drop=False)\n",
    "    return df\n",
    "    \n",
    "df_bolsa = only_bolsa(df_all)\n",
    "df_bolsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check (apagar)\n",
    "a = df_bolsa.loc[df_bolsa['ticker'] == 'ITSA4'].sort_values('data')\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesouro Direto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import local_lib as lib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1: Tabela Dinâmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados inputados pelo usuário.\n",
    "df_tesouro = pd.read_csv('../data/manutencao/dados_pos_home.csv')\n",
    "df_tesouro['data'] = pd.to_datetime(df_tesouro['data'], format='%Y-%m-%d')\n",
    "df_tesouro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os preços diários extraídos da API do Tesouro.\n",
    "df_hist_tesouro = etl_tesouro_historic_price()\n",
    "df_hist_tesouro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntando os dados do usuário com os dados da API.\n",
    "df_tesouro_historico = lib.merge_historic_tesouro(df_hist_tesouro, df_tesouro)\n",
    "df_tesouro_historico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo extra para criar uma coluna identificando o último dia do mês de cada ativo (útil para os plots)\n",
    "df_tesouro_historico = lib.create_column_last_day(df_tesouro_historico)\n",
    "df_tesouro_historico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar os tickers a serem visualizados (desnecessário neste notebook)\n",
    "'''\n",
    "# Filtro de tickers.\n",
    "list_ticker = st.multiselect('Escolha o(s) investimento(s):',\n",
    "                                df_tesouro_historico['ticker'].unique().tolist(),\n",
    "                                df_tesouro_historico['ticker'].unique().tolist())\n",
    "df_tesouro_historico = df_tesouro_historico.loc[df_tesouro_historico['ticker'].isin(list_ticker)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar os dados exclusivamente para a Tabela Dinâmica (visão 1)\n",
    "df_plot = df_tesouro_historico.loc[df_tesouro_historico['dummy_ultimo_dia'] == 1]\n",
    "tab1, data_col = lib.custom_pivot_table(df_plot, col_value='vl_atualizado')\n",
    "tab1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Gráfico de Linha com Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração das variações dos benchmarks (API do BC e yfinance)\n",
    "df_hist_bench = etl_benchmark_historic_price()\n",
    "df_hist_bench.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junção dos dados inputados pelo usuário e os dados históricos do benchmarks\n",
    "df_tesouro_historico_agg = lib.merge_historic_benchmark(df_tesouro_historico, df_hist_bench)\n",
    "df_tesouro_historico_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrumando dados em um formato melhor para o gráfico.\n",
    "tab2 = lib.custom_data_lineplot(df_tesouro_historico_agg, ['ibov', 'sp500', 'cdi', 'ipca'])\n",
    "tab2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3: KPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_interval = (datetime.datetime(2022, 7, 3), datetime.datetime(2022, 12, 1))\n",
    "date_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.DataFrame({'data': pd.date_range(df_tesouro_historico['data'].min().to_pydatetime() - datetime.timedelta(days=1),\n",
    "                                                df_tesouro_historico['data'].max().to_pydatetime())})\n",
    "df_kpi = pd.merge(df_date, df_tesouro_historico, on='data', how='left')\n",
    "df_kpi = df_kpi.groupby('data').agg({'qt':'sum', 'qt_acum':'sum',  'vl_atualizado':'sum'}).reset_index()\n",
    "df_kpi['vl_atualizado'] = np.where(df_kpi['qt_acum'] != 0, df_kpi['vl_atualizado'], np.nan)\n",
    "df_kpi['vl_atualizado'] = df_kpi['vl_atualizado'].fillna(method='ffill').fillna(0)\n",
    "df_kpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo dos aportes históricos.\n",
    "vl_aporte = df_tesouro_historico.loc[(df_tesouro_historico['qt'] != 0) &\n",
    "                                        (df_tesouro_historico['vl_total'] > 0) &\n",
    "                                        (df_tesouro_historico['data'] <= date_interval[1]), 'vl_total'].sum()\n",
    "\n",
    "vl_aporte_delta = df_tesouro_historico.loc[(df_tesouro_historico['qt'] != 0) &\n",
    "                                            (df_tesouro_historico['vl_total'] > 0) &\n",
    "                                            (df_tesouro_historico['data'].between(date_interval[0], date_interval[1])), 'vl_total'].sum()\n",
    "\n",
    "# Cálculo dos valores resgatados.\n",
    "vl_resgate = df_tesouro_historico.loc[(df_tesouro_historico['qt'] != 0) &\n",
    "                                        (df_tesouro_historico['vl_total'] < 0) &\n",
    "                                        (df_tesouro_historico['data'] <= date_interval[1]), 'vl_total'].sum()\n",
    "\n",
    "vl_resgate_delta = df_tesouro_historico.loc[(df_tesouro_historico['qt'] != 0) &\n",
    "                                            (df_tesouro_historico['vl_total'] < 0) &\n",
    "                                            (df_tesouro_historico['data'].between(date_interval[0], date_interval[1])), 'vl_total'].sum()\n",
    "\n",
    "# Cálculo do valor patrimonial.\n",
    "vl_patrimonio = df_kpi.loc[df_kpi['data'] == date_interval[1], 'vl_atualizado'].sum()\n",
    "vl_patrimonio_delta = vl_patrimonio - df_kpi.loc[df_kpi['data'] == date_interval[0], 'vl_atualizado'].sum()\n",
    "\n",
    "# Cálculo do rendimento.\n",
    "rendimento_nominal = round((vl_patrimonio - vl_resgate - vl_aporte) / vl_aporte * 100 , 1)\n",
    "if  vl_aporte_delta != 0:\n",
    "    rendimento_nominal_delta = round((vl_patrimonio_delta - vl_resgate_delta - vl_aporte_delta) / vl_aporte_delta * 100 , 1)\n",
    "else:\n",
    "    rendimento_nominal_delta = 0\n",
    "\n",
    "vl_aporte, vl_aporte_delta, vl_resgate, vl_resgate_delta, vl_patrimonio, vl_patrimonio_delta, rendimento_nominal, rendimento_nominal_delta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bolsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsa['data'] = pd.to_datetime(df_bolsa['data'], format='%Y-%m-%d')\n",
    "df_bolsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar lá encima!\n",
    "def etl_bolsa_historic_price(list_ticker_b3: list, start_date: str, end_date: str) -> np.array:\n",
    "\n",
    "    # Utilizando a api do yf\n",
    "    list_ticker_yf = [i + '.SA' for i in list_ticker_b3]\n",
    "    long_string = ' '.join(list_ticker_yf)\n",
    "\n",
    "    yf_df = yf.download(long_string, start=start_date, end=end_date, group_by='column', actions=True, interval='1wk')\n",
    "    yf_df_close = yf_df['Close'].reset_index().sort_values('Date', ascending=False).round(2).fillna(method='ffill')\n",
    "    yf_df_split = yf_df['Stock Splits'].reset_index().sort_values('Date', ascending=False).cumsum().round(2).fillna(method='ffill').replace(0, 1)\n",
    "\n",
    "    for i in list_ticker_yf:\n",
    "        yf_df_close[i] = yf_df_close[i] * (yf_df_split[i])\n",
    "\n",
    "    df_price = yf_df_close.sort_values('Date', ascending=True)\n",
    "\n",
    "    # Ajustes na base\n",
    "    df_price.columns = ['data'] + list(list_ticker_b3)    \n",
    "    df_price['data'] = pd.to_datetime(df_price['data'])\n",
    "    df_price = pd.melt(df_price, id_vars=['data'], value_vars=list(list_ticker_b3), var_name='ticker', value_name='preco')\n",
    "    \n",
    "    return df_price\n",
    "\n",
    "# Passo 1: extrair dados atualizados de cada ticker.\n",
    "df_bolsa_historico = etl_bolsa_historic_price(list_ticker_b3=df_bolsa['ticker'].sort_values().unique(),\n",
    "                                              start_date=df_bolsa['data'].min(),\n",
    "                                              end_date=df_bolsa['data'].max())\n",
    "df_bolsa_historico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Experimentando como usar o stock split\n",
    "start_date = df_bolsa.loc[df_bolsa['ticker'] == 'B3SA3', 'data'].dt.date.min()\n",
    "end_date = df_bolsa.loc[df_bolsa['ticker'] == 'B3SA3', 'data'].dt.date.max()\n",
    "long_string = 'B3SA3.SA ITSA4.SA'\n",
    "\n",
    "#start_date\n",
    "yf_df = yf.download(long_string, start=start_date, end=end_date, group_by='column', actions=True, interval='1wk')\n",
    "yf_df_close = yf_df['Close'].reset_index().sort_values('Date', ascending=False).round(2).fillna(method='ffill')\n",
    "yf_df_split = yf_df['Stock Splits'].reset_index().sort_values('Date', ascending=False).cumsum().round(2).fillna(method='ffill').replace(0, 1)\n",
    "\n",
    "display(df_bolsa.loc[df_bolsa['ticker'] == 'B3SA3'])\n",
    "#display(yf_df)\n",
    "display(yf_df_close.sort_values('Date'))\n",
    "display(yf_df_split.sort_index())\n",
    "\n",
    "for i in ['B3SA3.SA']:\n",
    "    yf_df_close[i] = yf_df_close[i] * (yf_df_split[i])\n",
    "\n",
    "df_price = yf_df_close.sort_values('Date', ascending=True)\n",
    "display(df_price)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2: juntar a carteira com os preços históricos.\n",
    "df_bolsa2 = pd.merge(df_bolsa_historico, df_bolsa, on=['data', 'ticker'], how='left').fillna(0)\n",
    "df_bolsa2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 3: calcular quantidade acumulada\n",
    "for i in df_bolsa['ticker'].sort_values().unique():\n",
    "    df_bolsa2.loc[df_bolsa2['ticker'] == i, 'qt_acum'] = df_bolsa2.loc[df_bolsa2['ticker'] == i, 'qt'].cumsum(skipna=True)\n",
    "    \n",
    "df_bolsa2['vl_atualizado'] = df_bolsa2['preco'] * df_bolsa2['qt_acum']\n",
    "df_bolsa_negociacao = df_bolsa2.loc[(df_bolsa2['qt'] != 0) | (df_bolsa2['qt_acum'] != 0)]\n",
    "\n",
    "display(df_bolsa_negociacao.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d7662bde5678ddf41fb482e2cda39dd85fc62406be2c88b1ebdc7b78e575873"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
